- 이미지 가져오는 명령어 : 
  docker image pull [쿠버네티스에서 가져올 배포된 이미지 명]
  docker image pull registry.secuiot/develop/dsp-ui-control:20200205.1_e51bc3457b1659a43df76966290cc0581d0f78a0

- 기존에 있는 이미지 배포 엑셀파일()을 통하여 아래 명령어을 생성 명령어 : 
  docker save -o [저장될 파일명] [저장할 파일로 변환할 이미지 명]
  docker save -o registry.secuiot-develop-dsp-ui-control-20200205-1_e51bc3457b1659a43df76966290cc0581d0f78a0.tar registry.secuiot/develop/dsp-ui-control:20200205.1_e51bc3457b1659a43df76966290cc0581d0f78a0


- Redis 사용법
  cd /usr/bin
  ./redis-cli
  - DB선택  : select {index}  -  default index는 0임
  - key 리스트 가져오기 : keys {인자}  - 예) keys ot_* : ot_ 로 시작하는 모든 key 리스트
  - 특정 key의 hashmap내 field의 값 가져오기 hget {key} {field} - 예) hget ot_505001 assetsid
  - 특정 key의 hashmap 다 가져오기 hgetall {key} - 예) hgetall ot_505001
  - 특정 key의 hashmap의 key들만 다 가져오기 hkeys {key} - 예) hkeys ot_505001
  - 특정 key의 hashmap의 value들만 다 가져오기 hkeys {key} - 예) hvals ot_505001
  - 특정 key의 hashmap내 field만 지우기 hdel {key} {field} - 예) hdel ot_505001 assetsid


[Kafka 실행]
D:\Tools\kafka_2.11-0.11.0.2\bin\windows 폴더로 이동

zookeeper-server-start.bat ..\..\config\zookeeper.properties
kafka-server-start.bat ..\..\config\server.properties

[Kafka Message]
kafka-console-producer.bat --broker-list localhost:9092 --topic [test]

kafka-console-consumer.bat --bootstrap-server localhost:9092 --topic [test]


[IntelliJ SSL 인증서 오류 해결방법]

curl -O https://gist.githubusercontent.com/lesstif/cd26f57b7cfd2cd55241b20e05b5cd93/raw/InstallCert.java  => 다운로드
javac InstallCert.java  => Compile
java -cp ./ InstallCert plugins.jetbrains.com  => Install
	1을 선택
keytool -exportcert -keystore jssecacerts -storepass changeit -file output.cert -alias plugins.jetbrains.com-1
keytool -importcert -keystore "C:\Program Files\JetBrains\IntelliJ IDEA Community Edition 2019.3.2\jbr\lib\security\cacerts" -storepass changeit -file output.cert -alias  plugins.jetbrains.com-1

java -cp ./ InstallCert plugins.jetbrains.com
	2를 선택
keytool -exportcert -keystore jssecacerts -storepass changeit -file output.cert -alias plugins.jetbrains.com-2
keytool -importcert -keystore "C:\Program Files\JetBrains\IntelliJ IDEA Community Edition 2019.3.2\jbr\lib\security\cacerts" -storepass changeit -file output.cert -alias  plugins.jetbrains.com-2

[Kafka 명령어]
1. topic
           1.1. topic create
                     ./kafka-topics.sh --zookeeper zk-svc:2181 --replication-factor [no] --partition [no] --topic [topicNm] --create

           1.2. topic list
                     ./kafka-topics.sh --zookeeper zk-svc:2181 --list

           1.3. topic detail
                      ./kafka-topics.sh --zookeeper zk-svc:2181 --describe --topic [topicNm]

           1.4. topic 보관주기 변경 (default 7일 = 604,800,000)
                확인 (default 속성이 아닌것 표시)
                ./kafka-configs.sh --zookeeper zk-svc:2181 --describe --entity-type topics --entity-name [topicNm]

                     1시간 = 3,600,000
                     ./kafka-configs.sh --zookeeper zk-svc:2181 --alter --entity-type topics --entity-name [topicNm] --add-config retention.ms=3600000

           1.5. topic 보관주기 설정을 삭제하기
                     ./kafka-configs.sh --zookeeper zk-svc:2181 --alter --entity-type topics --entity-name [topicNm] --delete-config retention.ms

2. producer
           2.1. message send (stdin)
                     ./kafka-console-producer.sh --broker-list kafka-svc:9093 --topic [topicNm]

           2.1. message send (from file)
                     ./kafka-console-producer.sh --broker-list kafka-svc:9093 --topic [topicNm] < filename

3. consumer
           3.1. message read (stdout)
                     ./kafka-console-consumer.sh --bootstrap-server kafka-svc:9093 --topic [topicNm]
                     ./kafka-console-consumer.sh --bootstrap-server kafka-svc:9093 --topic [topicNm] --from-beginning

           3.2. message read (specific offset)
                     opt/kafka/bin/kafka-console-consumer.sh --bootstrap-server kafka-svc:9093 --topic [topicNm] --partition [partitionNo] --offset [offsetNo] --max-messages [num]

           3.3. message read (with consumer group)
                     ./kafka-console-consumer.sh --bootstrap-server kafka-svc:9093 --topic [topicNm] -consumer-property group.id=[consumerGrpNm]

          3.4 consumer gropu list
                     ./kafka-consumer-groups.sh  --list --bootstrap-server kafka-svc:9093 

         3.5 consumer status and offset check! (offset & lag)
	./kafka-consumer-groups.sh  --bootstrap-server kafka-svc:9093 --group [consumberGN] --describe                     
	/opt/kafka/bin/kafka-consumer-groups.sh  --bootstrap-server kafka-svc:9093 --group simple1 --describe

	## 이거는 안 먹네...
               ./kafka-consumer-groups.sh --bootstrap-server kafka-svc:9093 --group simple1 --topic base-event --reset-offsets --to-earliest --execute
 

4. consumer group 
           4.1. list
                     ./kafka-consumer-groups.sh --bootstrap-server kafka-svc:9093 --list

           4.2. 상태확인
                     ./kafka-consumer-groups.sh --bootstrap-server kafka-svc:9093 --describe --group [consumerGrpNm]

* 현재 특정 topic, 특정 consumer group이 소모하고 있는 event확인은 다음 단계로 해라...
  1. 파티션별 현재 offset 확인 : /opt/kafka/bin/kafka-consumer-groups.sh  --bootstrap-server kafka-svc:9093 --group simple1 --describe
  2. 해당 offset의 데이터 확인 : /opt/kafka/bin/kafka-console-consumer.sh --bootstrap-server kafka-svc:9093 --topic [topicNm] --partition [partitionNo] --offset [offsetNo] --max-messages [num]

[kafka pods 상태 확인]
kubectl get po -w -o wide | grep kafka

kubectl label nodes [노드명] --overwrite [라벨명]=[값]
[라벨 제거 명령]
kubectl label nodes ds-node03 --overwrite dsaas-kafka-
kubernetes 대시보드에서 해당 pods를 delete

[라벨 새기는 명령]
label nodes ds-node03 --overwrite dsaas-kafka=true

[Front-End 빌드 및 테스트]
- Terminal 을 열고 초기에 한번만 npm install 수행
- npm run dev를 실행하면 빌드되고 실행됨
   *) package.json의 "scripts"에 정의된 build, dev, debug 옵션 중 하나를 선택해서 실행
       app-config.js에서 local test를 위해서는 https -> http로 변경, port를 :8200으로 변경해야 함
   *) hosts 파일에 아래 내용들을 등록해야 함.
       127.0.0.1 api.secudiumiot.com
       127.0.0.1 dsp-infra-eureka-lb
       127.0.0.1 dsp-infra-zipkin-lb
       127.0.0.1 redis-master-lb
       127.0.0.1 kafka-svc
       10.250.238.38 db.internal.secudiumiot.com


[zookeeper 명령어]
cd /opt/zookeeper/bin
./zkCli.sh
- node 생성
   create -[options] /[znode-name] [znode-data]
      persistent(기본값) : create /znode my_data
      Ephemeral : create ?e /eznode my_data
      Sequential : create ?s /sznode my_data
- node 읽기
   get /[znode_name]   
- node 데이터 설정
  set /[znode_name] [new_data]
- node 삭제
  delete /[znode_name]
- node 목록
  ls [znode_name]
